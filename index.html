<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="style.css">
  <title>SpeechJudge</title>
  <script src="./static/tailwind.js"></script>
  <script src="./static/vue.global.js"></script>
  <script src="./static/flowbite.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/papaparse@5.3.0/papaparse.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

  <style type="text/tailwindcss">
    @tailwind base;
    @tailwind components;
    @tailwind utilities;

    @layer base {
      a[href^="http"] {
        @apply text-blue-500;
      }

      a:hover {
        @apply text-blue-700 underline;
      }

      h1 {
        @apply mb-6 text-3xl font-bold text-gray-900 text-center;
      }

      h2 {
        @apply mb-3 pt-4 text-2xl font-bold tracking-tight text-gray-900;
      }

      h4 {
        @apply mb-4 pt-12 text-3xl font-semibold text-gray-900;
      }

      h5 {
        @apply mb-3 pt-4 text-2xl font-bold tracking-tight text-gray-900;
      }

      h6 {
        @apply mb-3 pt-4 text-xl font-bold tracking-tight text-gray-900;
      }

      p {
        @apply mb-4 font-normal text-gray-900 leading-relaxed;
      }
    }

    @layer components {
      .list-select {
        @apply block py-2 px-3 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0;
      }

      .tooltip {
        position: absolute;
        text-align: center;
        padding: 8px;
        font: 12px sans-serif;
        background: lightsteelblue;
        border: 0;
        border-radius: 8px;
        pointer-events: none;
        opacity: 0;
      }

      .text-p {
        @apply mb-4 font-normal text-gray-900 leading-relaxed;
      }

      .author {
        @apply font-medium mr-2 pb-1 text-gray-900 inline-block text-base;
      }

      .author a {
          @apply text-gray-900;
        }

      .affiliation {
        @apply font-medium mr-2 pb-1 text-gray-900 block text-base;
      }
    }
  </style>

  <script>
    tailwind.config = {
      theme: {
        extend: {
          colors: {}
        }
      }
    }
  </script>
</head>

<body>
  <div id="app">

    <nav class="bg-white fixed w-full z-20 top-0 start-0 border-gray-200 border-b border-gray-200"
      style="font-weight: bold;">
      <div class="max-w-screen-xl flex flex-wrap items-center justify-between mx-auto p-3">
        <button data-collapse-toggle="navbar-default" type="button"
          class="inline-flex items-center p-2 w-10 h-10 justify-center text-sm text-gray-500 rounded-lg md:hidden hover:bg-gray-100 focus:outline-none focus:ring-2 focus:ring-gray-200"
          aria-controls="navbar-default" aria-expanded="false">
          <span class="sr-only">Open main menu</span>
          <svg class="w-5 h-5" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 17 14">
            <path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
              d="M1 1h15M1 7h15M1 13h15" />
          </svg>
        </button>

        <div class="hidden w-full md:block md:w-auto ml-auto" id="navbar-default">
          <ul
            class="font-medium flex flex-col p-4 md:p-0 mt-4 border border-gray-100 rounded-lg bg-gray-50 md:flex-row md:space-x-8 rtl:space-x-reverse md:mt-0 md:border-0 md:bg-white">
            <li>
              <a href="#home" class="list-select"><b>Home</b></a>
            </li>
            <li>
              <a href="#data" class="list-select"><b>SpeechJudge-Data</b></a>
            </li>
            <li>
              <a href="#eval" class="list-select"><b>SpeechJudge-Eval</b></a>
            </li>
            <li>
              <a href="#grm" class="list-select"><b>SpeechJudge-GRM</b></a>
            </li>
            <li>
              <a href="#applications" class="list-select"><b>Applications</b></a>
            </li>
          </ul>
        </div>
      </div>
    </nav>


    <div class="p-4 mt-24 max-w-screen-xl mx-auto" id="home">
      <div class="mt-16 mb-8">
        <h1>SpeechJudge: Towards Human-Level Judgment for Speech Naturalness</h1>
      </div>

      <div class="max-w-screen-xl mx-auto mt-8 mb-16">
        <div class="text-center h-2 flex flex-col gap-3">
        </div>

        <div class="max-w-[900px] flex flex-col mx-auto mt-8 mb-16">
          <h2>Abstract</h2>
          <p class="text-p">
            Aligning large generative models with human feedback is a critical challenge. In
            speech synthesis, this is particularly pronounced due to the lack of a large-scale
            human preference dataset, which hinders the development of models that truly
            align with human perception. To address this, we introduce <b><i>SpeechJudge</i></b>, a comprehensive suite
            comprising a dataset, a benchmark, and a reward model centered
            on naturalnessâ€”one of the most fundamental subjective metrics for speech synthesis. First, we present
            <b><i>SpeechJudge-Data</i></b>, a large-scale human feedback corpus
            of 99K speech pairs. The dataset is constructed using a diverse set of advanced
            zero-shot text-to-speech (TTS) models across diverse speech styles and multiple
            languages, with human annotations for both intelligibility and naturalness preference. From this, we
            establish <b><i>SpeechJudge-Eval</i></b>, a challenging benchmark for
            speech naturalness judgment. Our evaluation reveals that existing metrics and AudioLLMs struggle with this
            task; the best-performing model, Gemini-2.5-Flash,
            achieves less than 70% agreement with human judgment, highlighting a significant
            gap for improvement. To bridge this gap, we develop <b><i>SpeechJudge-GRM</i></b>,
            a generative reward model (GRM) based on Qwen2.5-Omni-7B. It is trained on
            SpeechJudge-Data via a two-stage post-training process: Supervised Fine-Tuning
            (SFT) with Chain-of-Thought rationales followed by Reinforcement Learning
            (RL) with GRPO on challenging cases. On the <b><i>SpeechJudge-Eval</i></b> benchmark,
            the proposed <b><i>SpeechJudge-GRM</i></b> demonstrates superior performance, achieving
            77.2% accuracy (and 79.4% after inference-time scaling @10) compared to a classic
            Bradley-Terry reward model (72.7%). Furthermore, SpeechJudge-GRM can be
            also employed as a reward function during the post-training of speech generation
            models to facilitate their alignment with human preferences.
          </p>
        </div>


        <div class="mt-8 mb-8" id="data">
          <h4>SpeechJudge-Data</h4>
          <p>
            The raw dataset consists of 99K human-annotated speech pairs. It is generated using a diverse set of
            advanced zero-shot TTS models. Each pair is annotated by at least 2 human raters for both intelligibility
            and naturalness preference.
          </p>
          <img class="py-4 max-w-screen-md mx-auto" src="img/system-ui.png" alt="Annotation System UI">
          <img class="py-4 max-w-screen-md mx-auto" src="img/data_distribution.png" alt="Data Distribution">
          <img class="py-4 max-w-[400px] mx-auto" src="img/data_pairs.png" alt="Data Pairs">
        </div>

        <div class="mt-8" id="eval">
          <h4>SpeechJudge-Eval</h4>

          <div class="relative overflow-x-auto shadow-md sm:rounded-lg mb-8">
            <table class="w-full text-sm text-left rtl:text-right min-w-[800px]">
              <thead class="text-sm text-gray-900 font-bold bg-gray-50">
                <tr>
                  <th scope="col" class="px-6 py-3 w-[15%]">Prompt</th>
                  <th scope="col" class="px-6 py-3 w-[25%]">Target Text</th>
                  <th scope="col" class="px-6 py-3 w-[15%]">Audio A</th>
                  <th scope="col" class="px-6 py-3 w-[15%]">Audio B</th>
                  <th scope="col" class="px-6 py-3 w-[10%]">A Spell Wrong</th>
                  <th scope="col" class="px-6 py-3 w-[10%]">B Spell Wrong</th>
                  <th scope="col" class="px-6 py-3 w-[10%]">Naturalness Result</th>
                </tr>
              </thead>
              <tbody>
                <template v-for="(item, index) in eval_data" :key="index">
                  <tr class="bg-white border-b hover:bg-gray-50">
                    <td>
                      <play-audio :src="item.prompt_wav_path"></play-audio>
                    </td>
                    <td>{{ item.target_text }}</td>
                    <td>
                      <play-audio :src="item.audioA"></play-audio>
                    </td>
                    <td>
                      <play-audio :src="item.audioB"></play-audio>
                    </td>
                    <td>
                      <span
                        :class="{'text-red-500': item.audioA_spell_wrong === '1', 'text-green-500': item.audioA_spell_wrong === '0'}">
                        {{ item.audioA_spell_wrong === '1' ? 'Yes' : 'No' }}
                      </span>
                    </td>
                    <td>
                      <span
                        :class="{'text-red-500': item.audioB_spell_wrong === '1', 'text-green-500': item.audioB_spell_wrong === '0'}">
                        {{ item.audioB_spell_wrong === '1' ? 'Yes' : 'No' }}
                      </span>
                    </td>
                    <td>{{ item.naturalness_result }}</td>
                  </tr>
                </template>
              </tbody>
            </table>
          </div>
        </div>

        <div class="mt-8" id="grm">
          <h4>SpeechJudge-GRM</h4>
          <div class="flex flex-col mx-auto mt-8 mb-16 p-6 bg-gray-50 rounded-lg">
            <div v-if="grm_data.length > 0">
              <!-- Case selection buttons -->
              <ul class="flex flex-wrap justify-center mb-6">
                <li v-for="(item, index) in grm_data" :key="index" class="me-2 mb-2">
                  <a href="#" @click.prevent="selectGrmEntry(index)"
                    :class="{'bg-gray-900 text-white hover:text-white': currentGrmIndex === index, 'bg-gray-200 text-gray-800 hover:text-gray-800 hover:bg-gray-300': currentGrmIndex !== index}"
                    class="inline-flex items-center justify-center min-w-[120px] px-4 py-2.5 rounded-lg transition-all duration-200 font-medium">
                    <span class="relative">Case {{ index + 1 }}</span>
                  </a>
                </li>
              </ul>

              <!-- User Prompt Section -->
              <div class="flex flex-row">
                <span class="font-bold text-base text-right pr-4 w-1/6">Prompt</span>
                <div class="w-5/6">
                  <div class="flex items-center mb-4">
                    <p class="text-p m-0">
                      We are comparing the naturalness of two text-to-speech models' outputs. The models need to speak
                      the target text accurately and naturally.
                    </p>
                  </div>
                  <p class="text-p">
                    Target text: {{ currentGrmEntry.target_text }}.
                  </p>
                  <strong class="mb-2">Output A:</strong>
                  <play-audio :src="currentGrmEntry.audioA"></play-audio>
                  <strong class="mb-2">Output B:</strong>
                  <play-audio :src="currentGrmEntry.audioB"></play-audio>
                  <p class="text-p">
                    Analyze the two output above, and score them with number from 1 to 10.
                  </p>
                  <p class="text-p">
                    Note:
                  </p>
                  <p class="text-p">
                    (1) Please evaluate the naturalness of both audio outputs based on the following criteria: *Prosody
                    and Intonation*, *Pacing and Rhythm*, *Articulation and Clarity*, and *Overall Naturalness*.
                  </p>
                  <p class="text-p">
                    (2) After conducting a detailed analysis of each criterion, using the following output template to
                    highlight your conclusion: Output A: X, Output B: X.
                  </p>
                </div>
              </div>

              <!-- Completion Section -->
              <div class="flex flex-row mt-6">
                <div class="flex flex-col items-end pr-4 w-1/6">
                  <span class="font-bold text-base text-right">SpeechJudge-GRM</span>
                  <!-- Completion selection buttons -->
                  <ul class="flex flex-col gap-2 mt-3 text-sm">
                    <li class="me-2">
                      <a href="#" @click.prevent="selectCompletion(0)"
                        :class="{'bg-blue-50 text-blue-600 ring-1 ring-blue-600/20': currentCompletionIndex === 0, 'text-gray-600 hover:bg-gray-50 hover:text-gray-900': currentCompletionIndex !== 0}"
                        class="inline-flex items-center justify-center min-w-[100px] px-3 py-1.5 rounded-lg transition-all duration-200 text-sm">
                        <span class="relative">Completion 1</span>
                      </a>
                    </li>
                    <li class="me-2">
                      <a href="#" @click.prevent="selectCompletion(1)"
                        :class="{'bg-blue-50 text-blue-600 ring-1 ring-blue-600/20': currentCompletionIndex === 1, 'text-gray-600 hover:bg-gray-50 hover:text-gray-900': currentCompletionIndex !== 1}"
                        class="inline-flex items-center justify-center min-w-[100px] px-3 py-1.5 rounded-lg transition-all duration-200 text-sm">
                        <span class="relative">Completion 2</span>
                      </a>
                    </li>
                    <li class="me-2">
                      <a href="#" @click.prevent="selectCompletion(2)"
                        :class="{'bg-blue-50 text-blue-600 ring-1 ring-blue-600/20': currentCompletionIndex === 2, 'text-gray-600 hover:bg-gray-50 hover:text-gray-900': currentCompletionIndex !== 2}"
                        class="inline-flex items-center justify-center min-w-[100px] px-3 py-1.5 rounded-lg transition-all duration-200 text-sm">
                        <span class="relative">Completion 3</span>
                      </a>
                    </li>
                  </ul>
                </div>
                <div class="w-5/6 text-gray-800">
                  <div v-html="currentCompletionHtml"></div>
                </div>
              </div>
            </div>
            <div v-else class="text-center text-gray-500">
              Loading SpeechJudge-GRM data...
            </div>
          </div>
        </div>

        <div class="mt-8" id="applications">
          <h4>Applications</h4>

          <h5 class="mb-3 pt-4 text-2xl font-bold tracking-tight text-gray-900">A. Post-training on Qwen2.5-0.5B-TTS
          </h5>
          <p class="text-p">
            Compare base model vs. four alignment settings:
          </p>
          <div class="relative overflow-x-auto shadow-md sm:rounded-lg mb-8">
            <table class="w-full text-sm text-left rtl:text-right min-w-[800px]">
              <thead class="text-sm text-gray-900 font-bold bg-gray-50">
                <tr>
                  <th scope="col" class="px-6 py-3 w-[15%]">Prompt</th>
                  <th scope="col" class="px-6 py-3 w-[25%]">Target Text</th>
                  <th scope="col" class="px-6 py-3 w-[15%]">Base</th>
                  <th scope="col" class="px-6 py-3 w-[15%]">SpeechJudge-Data</th>
                  <th scope="col" class="px-6 py-3 w-[15%]">SpeechJudge-GRM (offline)</th>
                  <th scope="col" class="px-6 py-3 w-[15%]">SpeechJudge-GRM (online)</th>
                </tr>
              </thead>
              <tbody>
                <template v-for="(item, index) in tts_enhence_data" :key="index">
                  <tr class="bg-white border-b hover:bg-gray-50">
                    <td>
                      <play-audio :src="item.prompt"></play-audio>
                    </td>
                    <td>{{ item.target_text }}</td>
                    <td>
                      <play-audio :src="item.base"></play-audio>
                    </td>
                    <td>
                      <play-audio :src="item.data"></play-audio>
                    </td>
                    <td>
                      <play-audio :src="item.offline"></play-audio>
                    </td>
                    <td>
                      <play-audio :src="item.online"></play-audio>
                    </td>
                  </tr>
                </template>
              </tbody>
            </table>
          </div>

          <h5 class="mb-3 pt-4 text-2xl font-bold tracking-tight text-gray-900">B. Best-of-N Selection for Qwen2.5-Omni
            (Talker)</h5>
          <div class="relative overflow-x-auto shadow-md sm:rounded-lg mb-8">
            <table class="w-full text-sm text-left rtl:text-right min-w-[800px]">
              <thead class="text-sm text-gray-900 font-bold bg-gray-50">
                <tr>
                  <th scope="col" class="px-6 py-3 w-[40%]">Target Text</th>
                  <th scope="col" class="px-6 py-3 w-[20%]">Random</th>
                  <th scope="col" class="px-6 py-3 w-[20%]">SpeechJudge-BTRM</th>
                  <th scope="col" class="px-6 py-3 w-[20%]">SpeechJudge-GRM</th>
                </tr>
              </thead>
              <tbody>
                <template v-for="(item, index) in qwen_select_data" :key="index"
                  class="bg-white border-b hover:bg-gray-50">
                  <tr>
                    <td>{{ item.target_text }}</td>
                    <td>
                      <play-audio :src="item.random"></play-audio>
                    </td>
                    <td>
                      <play-audio :src="item.btrm"></play-audio>
                    </td>
                    <td>
                      <play-audio :src="item.grm"></play-audio>
                    </td>
                  </tr>
                </template>
              </tbody>
            </table>
          </div>
        </div>
      </div>

    </div>
  </div>

  <script>
    const { createApp, ref, onMounted, computed } = Vue

    const PlayAudio = {
      props: ['src'],
      template: `
        <audio controls class="w-full">
          <source :src="encodeURIComponent(src)" type="audio/wav">
          Your browser does not support the audio element.
        </audio>
      `,
      methods: {
        encodeURIComponent: encodeURIComponent
      }
    }

    createApp({
      components: {
        'play-audio': PlayAudio
      },
      setup() {

        const tts_enhence_data = ref([]);
        const qwen_select_data = ref([]);
        const eval_data = ref([]);
        const grm_data = ref([]);
        const currentGrmIndex = ref(0);
        const currentCompletionIndex = ref(0);

        const currentGrmEntry = computed(() => {
          return grm_data.value[currentGrmIndex.value] || {};
        });

        const currentCompletionHtml = computed(() => {
          const entry = currentGrmEntry.value;
          switch (currentCompletionIndex.value) {
            case 0: return entry.completions1_html;
            case 1: return entry.completions2_html;
            case 2: return entry.completions3_html;
            default: return '';
          }
        });

        const selectGrmEntry = (index) => {
          currentGrmIndex.value = index;
          currentCompletionIndex.value = 0; // Reset completion index when changing entry
        };

        const selectCompletion = (index) => {
          currentCompletionIndex.value = index;
        };

        onMounted(() => {
          Papa.parse('SpeechJudge_subeval/tts_enhence.csv', {
            download: true,
            header: true,
            complete: (results) => {
              tts_enhence_data.value = results.data;
            },
            error: (error) => {
              console.error('Error fetching or parsing tts_enhence.csv:', error);
            }
          });

          Papa.parse('SpeechJudge_subeval/qwen_select.csv', {
            download: true,
            header: true,
            complete: (results) => {
              qwen_select_data.value = results.data;
            },
            error: (error) => {
              console.error('Error fetching or parsing qwen_select.csv:', error);
            }
          });

          Papa.parse('SpeechJudge_eval/eval.csv', {
            download: true,
            header: true,
            complete: (results) => {
              eval_data.value = results.data;
            },
            error: (error) => {
              console.error('Error fetching or parsing eval.csv:', error);
            }
          });

          Papa.parse('SpeechJudge_eval/grm.csv', {
            download: true,
            header: true,
            complete: (results) => {
              grm_data.value = results.data.map(item => {
                return {
                  ...item,
                  completions1_html: marked.parse(item.completions1 || ''),
                  completions2_html: marked.parse(item.completions2 || ''),
                  completions3_html: marked.parse(item.completions3 || '')
                };
              }).filter(item => item.target_text); // Filter out empty rows
            },
            error: (error) => {
              console.error('Error fetching or parsing grm.csv:', error);
            }
          });
        });

        return {
          tts_enhence_data,
          qwen_select_data,
          eval_data,
          grm_data,
          currentGrmIndex,
          currentCompletionIndex,
          currentGrmEntry,
          currentCompletionHtml,
          selectGrmEntry,
          selectCompletion
        }
      }
    }).mount('#app')
  </script>

</body>

</html>